{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Engineering_Research.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHHigWeBkJclUH4pk66fvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jarred-ZA/FPAI_Wind/blob/main/Feature_Engineering_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQkMgeI4E6kH"
      },
      "source": [
        "**Feature Engineering - AI for wind energy**\n",
        "\n",
        "*This is a working document to allow for the extraction, manipulation and interogation of the provided datasets*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC3eTzH9Fr0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5495afd-454b-432e-d385-1caf943b3704"
      },
      "source": [
        "!pip install wget\n",
        "!pip install zenodo-get\n",
        "!pip install lvm-read\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=9d5956f91b24aaeb40e86838e5fe7de89cfd296e226fd99d9e5cd0c1ecc7fa6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting zenodo-get\n",
            "  Downloading zenodo_get-1.3.4-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (from zenodo-get) (3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from zenodo-get) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->zenodo-get) (2.10)\n",
            "Installing collected packages: zenodo-get\n",
            "Successfully installed zenodo-get-1.3.4\n",
            "Collecting lvm-read\n",
            "  Downloading lvm_read-1.20-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lvm-read) (1.19.5)\n",
            "Installing collected packages: lvm-read\n",
            "Successfully installed lvm-read-1.20\n",
            "Drive not mounted, so nothing to flush and unmount.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E90FBBVcEj9x"
      },
      "source": [
        "#Import relvant libiarys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.fft import fft, ifft, fftfreq\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat \n",
        "import os\n",
        "import zenodo_get\n",
        "import lvm_read\n",
        "import io\n",
        "from io import BytesIO\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pyOQJVmG1Fu",
        "outputId": "33b204e1-fd94-47ce-c8ec-8375f7bd576c"
      },
      "source": [
        "# Clone dataset A repo\n",
        "!git clone https://github.com/ETH-WindMil/Sonkyo-Benchmark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sonkyo-Benchmark'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 196 (delta 5), reused 8 (delta 0), pack-reused 170\u001b[K\n",
            "Receiving objects: 100% (196/196), 4.27 MiB | 28.73 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0tlnYVUZNoo"
      },
      "source": [
        "!zenodo_get -r 3229743 -w urls.txt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v-madE9jEDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "80d758ae-6f07-40a9-f5ab-e8b56d2d3c92"
      },
      "source": [
        "with open(\"urls.txt\", \"r\") as f:\n",
        "    urls = f.read().splitlines()\n",
        "    f.close()\n",
        "\n",
        "#Download 1 folder\n",
        "urls_np = np.array(urls)\n",
        "get_url = \"\\'{}\\'\".format(urls_np[0])\n",
        "#!wget -nc $get_url -O zipfile\n",
        "zf = ZipFile('zipfile')\n",
        "for file in zf.namelist():\n",
        "    # read lvm files \n",
        "    if (file.endswith('lvm')):\n",
        "        with zf.open(file, 'r') as lvm:\n",
        "            buf=io.BytesIO()\n",
        "            for line in lvm:\n",
        "                buf.write(line)\n",
        "                if line[0:3]=='***':\n",
        "                    #Everything before was a header, make a new buffer\n",
        "                    buf.close()\n",
        "                    buf=io.BytesIO()\n",
        "        buf.seek(0)\n",
        "        df = pd.read_csv(buf,sep='\\t', skiprows=22) \n",
        "        df['file_name'] = file\n",
        "        df.to_csv(f\"/content/{case}.csv\", mode='a', header=not(os.path.exists(f\"/content/{case}.csv\")), index=False)\n",
        "\n",
        "    # read description files \n",
        "    if (file.endswith('txt')):\n",
        "        with zf.open(file, 'r') as txt:\n",
        "            buf=io.BytesIO()\n",
        "            for line in txt:\n",
        "                buf.write(line)\n",
        "            buf.seek(0)\n",
        "            df = pd.read_csv(buf, header=None, names = ['data'])\n",
        "            df['var'] = df['data'].str.replace('\\t', '').str.split(':').str[0]\n",
        "            df['val'] = df['data'].str.replace('\\t', '').str.split(':').str[1]\n",
        "            df.pop('data')\n",
        "            df = df.set_index('var').transpose().reset_index()\n",
        "            df['file_name'] = file\n",
        "            dfs.append (df)                "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-eac834b7d749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"urls.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Download 1 folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'urls.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IiaoQln1peU"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUQ77cLYod3s"
      },
      "source": [
        "df_a = pd.read_csv(\"Case_A.csv\", nrows=100)\n",
        "df_a.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwH37gYhlYIr"
      },
      "source": [
        "        # read description files \n",
        "        if (file.endswith('txt')):\n",
        "            with zipfile.open(file, 'r') as txt:\n",
        "                buf=io.BytesIO()\n",
        "                for line in txt:\n",
        "                    buf.write(line)\n",
        "                buf.seek(0)\n",
        "                df = pd.read_csv(buf, header=None, names = ['data'])\n",
        "                df['var'] = df['data'].str.replace('\\t', '').str.split(':').str[0]\n",
        "                df['val'] = df['data'].str.replace('\\t', '').str.split(':').str[1]\n",
        "                df.pop('data')\n",
        "                df = df.set_index('var').transpose().reset_index()\n",
        "                df['file_name'] = file\n",
        "                dfs.append (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5g765TXbiUr"
      },
      "source": [
        "with open(\"urls.txt\", \"r\") as f:\n",
        "    urls = f.read().splitlines()\n",
        "    f.close()\n",
        "\n",
        "#Download 1 folder\n",
        "urls_np = np.array(urls)\n",
        "get_url = \"\\'{}\\'\".format(urls_np[0])\n",
        "if not(os.path.isdir('Data_Folder')):\n",
        "    !wget -nc $get_url -O Data_Folder.zip\n",
        "    !unzip 'Data_Folder.zip' -d Data_Folder\n",
        "    !rm 'Data_Folder.zip'\n",
        "\n",
        "filename = '/content/Data_Folder/Case_A_(+00)/Case_A_(+00)_1/sine_sweep.lvm'\n",
        "lvm = lvm_read.read(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkCpHO-c6J92"
      },
      "source": [
        "Channels = lvm[0]['Channel names']\n",
        "print(Channels.index('Ch2'))\n",
        "i = Channels.index('Ch2') \n",
        "plt.plot(lvm[0]['data'][:,i]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKIcBHEcAjws"
      },
      "source": [
        "# Some dummy data\n",
        "time = np.linspace(0,np.pi*10,1000)\n",
        "noise = [random.uniform(-2,2) for i in range(len(time))]\n",
        "noisy_signal =  np.sin(time) + np.cos(time+np.pi*time) + noise\n",
        "clean_signal = np.sin(time) + np.cos(time+np.pi*time)\n",
        "\n",
        "# Apply FFT\n",
        "fft_coefficients = fft(noisy_signal) # fourier transform\n",
        "fft_coefficients\n",
        "\n",
        "# plot orignal signal and inverse fourier transform, shows you can transform signal to frequency domain, then back to time domain\n",
        "fiax = plt.subplots(figsize=(15,6))\n",
        "ax.plot(time,noisy_signal,'-',label='Nosiy signal')\n",
        "ax.plot(time,clean_signal,'-',label='Clean signal')\n",
        "ax.set_xlabel('Timesteps')\n",
        "ax.legend()\n",
        "ax.tick_params(rotation=30,labelsize=15)\n",
        "plt.tight_layout()\n",
        "plt.title('Clean vs Noisy signal')\n",
        "\n",
        "# plot amplitude vs frequency \n",
        "n = len(signal)\n",
        "\n",
        "# get frequencies and psd\n",
        "freqs = fftfreq(noisy_signal.shape[0]) # x axis of amplitude vs frequency graphs\n",
        "psd = np.abs(fft_coefficients)/n # psd is amplitude/N, psd or power spectrum density is the magnitude of the coefficients resulting from fourier transform\n",
        "\n",
        "# plot psd\n",
        "fig,ax = plt.subplots(figsize=(15,6))\n",
        "ax.plot(freqs[1:int(n/2)],psd[1:int(n/2)])\n",
        "ax.set_ylabel('Power spectrum',fontsize=15)\n",
        "ax.set_xlabel('Frequencies',fontsize=15)\n",
        "ax.set_title('FFT')\n",
        "ax.tick_params(labelsize=15)\n",
        "plt.tight_layout()\n",
        "plt.title('FFT results')\n",
        "\n",
        "# lets filter out some signal\n",
        "\n",
        "# Threshold coefficients to denoise signal\n",
        "psd_indices = psd > 0.15 # mask\n",
        "fft_filtered = fft_coefficients*psd_indices\n",
        "\n",
        "# inverse transform filter coefficients\n",
        "inverse_transform_filtered = ifft(fft_filtered)\n",
        "\n",
        "# plot this\n",
        "fig,ax = plt.subplots(figsize=(15,6))\n",
        "ax.plot(time,inverse_transform_filtered,'-',label='Inverse fourier filtered')\n",
        "ax.legend()\n",
        "ax.set_title('Threshold = 0.01')\n",
        "ax.set_xlabel('Timesteps',fontsize=15)\n",
        "ax.tick_params(rotation=30,labelsize=15)\n",
        "plt.tight_layout()\n",
        "plt.title('Denoised signal')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}